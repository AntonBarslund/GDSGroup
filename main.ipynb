{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from cleantext.clean import clean\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/news_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to data/news_sample_1.csv\n"
     ]
    }
   ],
   "source": [
    "def clean_text_library(text):\n",
    "    return clean(str(text),  # Convert to string in case of non-string input\n",
    "        fix_unicode=True,               \n",
    "        to_ascii=True,                  \n",
    "        lower=True,                     \n",
    "        no_line_breaks=True,            \n",
    "        lang=\"en\"                       \n",
    "    )\n",
    "df['content'] = df['content'].astype(str).apply(clean_text_library)\n",
    "\n",
    "# Save cleaned data\n",
    "output_path = 'data/news_sample_1.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Cleaned data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex patterns \n",
    "patterns = {\n",
    "    r\"[\\w]+ [\\d]+, [\\d]+\": \"\",                    # DATE method 1\n",
    "    r\"[\\d]+[\\w]+ [\\w]+ [\\d]+\": \"\",                # DATE method 2\n",
    "    r\"[\\d]+\\/?-?\\.?[\\d]+\\/?-?\\.?[\\d]+\": \"\",       # DATE method 3 (fixed brackets)\n",
    "    r\"[\\w]+ \\d\\d?[\\w]?[\\w]?,? [\\d]{2,4}\": \"\",     # DATE method 4\n",
    "    r\"([\\d]{1,2}[\\w]*) ([\\w]*),? ([\\d]{2,4})\": \"\",# DATE method 5 (fixed range)\n",
    "    r\"\\b(\\d+(st|nd|rd|th|s))\\b\": \"\"                # NUM\n",
    "}\n",
    "\n",
    "def clean_dates(df):\n",
    "    for pattern, replacement in patterns.items():\n",
    "        df['content'] = df['content'].str.replace(pattern, replacement, regex=True)\n",
    "    return df\n",
    "\n",
    "df = clean_dates(df)\n",
    "df.to_csv('data/news_sample_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_library(text):\n",
    "    return clean(text,\n",
    "    no_urls=True,                  \n",
    "    no_emails=True,               \n",
    "    no_phone_numbers=True,        \n",
    "    no_numbers=True,               \n",
    "    no_digits=True,                \n",
    "    no_currency_symbols=True,      \n",
    "    no_punct=True,                \n",
    "    replace_with_punct=\"\",          \n",
    "    replace_with_url=\"\",\n",
    "    replace_with_email=\"\",\n",
    "    replace_with_phone_number=\"\",\n",
    "    replace_with_number=\"\",\n",
    "    replace_with_digit=\"0\",\n",
    "    replace_with_currency_symbol=\"\",\n",
    "    lang=\"en\"                       \n",
    ")\n",
    "# Cleaning the content column of the dataset\n",
    "df['content'] = df['content'].apply(clean_text_library)\n",
    "df.to_csv('data/news_sample_3.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the content column of the dataset\n",
    "df['content'] = df['content'].apply(word_tokenize)\n",
    "df.to_csv('data/news_sample_4.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def rs(list):\n",
    "    return [word for word in list if word.lower() not in stop_words]\n",
    "\n",
    "df['content'] = df['content'].apply(rs)\n",
    "df.to_csv('data/news_sample_5.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def setmming(list):\n",
    "    return [stemmer.stem(word) for word in list]\n",
    "\n",
    "df['content'] = df['content'].apply(setmming)\n",
    "df.to_csv('data/news_sample_6.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the df_5_content text: 16371\n",
      "Number of unique words in the df_6_content text: 10958\n",
      "0.6693543460998106\n"
     ]
    }
   ],
   "source": [
    "# Defines the regex for finding words  \n",
    "word_pattern = re.compile(r\"\\b\\w+\\b\")\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df_5 = pd.read_csv('data/news_sample_5.csv')\n",
    "df_6 = pd.read_csv('data/news_sample_6.csv')\n",
    "# Extracting all words of the \"news_sample.csv\" and the cleaned version\n",
    "df_5_content = \" \".join(df_5[\"content\"].astype(str))\n",
    "df_6_content = \" \".join(df_6[\"content\"].astype(str))\n",
    "\n",
    "df_5_content = word_pattern.findall(df_5_content)\n",
    "df_6_content = word_pattern.findall(df_6_content)\n",
    "\n",
    "# Extracting all unique words of the \"news_sample.csv\" and the cleaned version\n",
    "len_df_5_content = len(set(df_5_content))\n",
    "len_df_6_content = len(set(df_6_content))\n",
    "\n",
    "# Printing the unique words of the raw version, and the unique words after it has been cleaned \n",
    "print(f\"Number of unique words in the df_5_content text: {len_df_5_content}\")\n",
    "print(f\"Number of unique words in the df_6_content text: {len_df_6_content}\")\n",
    "\n",
    "print(len_df_6_content/len_df_5_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
